# Vericoding - Raw Benchmarks

## DafnyBench
https://github.com/sun-wendy/DafnyBench

## HumanEval
https://github.com/openai/human-eval

## NumPy
(BAIF internal)

## Verina
https://github.com/sunblaze-ucb/verina

## APPS
https://github.com/hendrycks/apps

## Clever
https://github.com/trishullab/clever

The Lean and Rust files from the Clever benchmark are in the `benchmarks/raw/humaneval` folder. HumanEval problems 22, 137, 162 are missing from Clever for reasons mentioned in the Clever paper.


crea 0
manip 1
bitwise 1
const 0
data 2
datetime 2
fft 3/4
index 2
io_op 1
linalg 2
logic 1
math 1
ndarr  0
poly 3
rand 2
set 2
sort 1
stat 3
strin 1
test  ignore
typing  1
ufunc 1 (core)
ufuncs 1  (lifting vect)
